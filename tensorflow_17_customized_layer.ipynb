{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.0\n",
      "sys.version_info(major=3, minor=8, micro=2, releaselevel='final', serial=0)\n",
      "matplotlib 3.2.1\n",
      "numpy 1.18.5\n",
      "pandas 1.0.4\n",
      "sklearn 0.23.1\n",
      "tensorflow 2.2.0\n",
      "tensorflow.keras 2.3.0-tf\n"
     ]
    }
   ],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "\n",
    "print(tf.__version__)\n",
    "print(sys.version_info)\n",
    "for module in mpl, np, pd, sklearn, tf, keras:\n",
    "    print(module.__name__, module.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10, 100), dtype=float32, numpy=\n",
       "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 神经网络中，层的理解\n",
    "layer = tf.keras.layers.Dense(100)  # 100表示的是神经元的个数\n",
    "layer = tf.keras.layers.Dense(100, input_shape=(None, 5))  # 指定输入的数据形状，表示该层规模是none*5*100（层数）\n",
    "layer(tf.zeros([10, 5]))  # 输入零矩阵，规模为10*5，那么矩阵运算后输出则为10*100（M10*5 x N5*100 = P10*100）\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'dense_4/kernel:0' shape=(5, 100) dtype=float32, numpy=\n",
       " array([[-0.00516658,  0.16830744,  0.10691567, -0.22209494, -0.06649332,\n",
       "          0.05231564,  0.15315811, -0.09568574,  0.09581386, -0.05721094,\n",
       "          0.0339296 ,  0.07436655,  0.12737592,  0.03646921,  0.23837589,\n",
       "         -0.120244  ,  0.01287107, -0.04214725,  0.10307647, -0.17928588,\n",
       "          0.18581615,  0.22529308,  0.16231619, -0.23440531, -0.21285775,\n",
       "         -0.0251063 , -0.08228214,  0.03245674,  0.09435289, -0.02554134,\n",
       "         -0.18795732,  0.01307149, -0.05182236,  0.03192033, -0.15838663,\n",
       "          0.08954953, -0.15672375, -0.04879673,  0.06885518,  0.18610577,\n",
       "         -0.02400839, -0.09453568,  0.2021644 , -0.21577266, -0.1640091 ,\n",
       "         -0.17140542, -0.02432066,  0.11728613, -0.03578222, -0.06294683,\n",
       "          0.01608585,  0.05855079,  0.00970368, -0.02924605, -0.19812946,\n",
       "          0.03949587,  0.18871959, -0.09425402, -0.22173081,  0.02184044,\n",
       "         -0.08302584, -0.12884018,  0.09550656,  0.11684261, -0.1650645 ,\n",
       "         -0.07400031, -0.21054265, -0.03787221,  0.02960138,  0.22187705,\n",
       "          0.07314532,  0.11003558, -0.11766295,  0.16839425, -0.12722455,\n",
       "         -0.18331876,  0.1026981 , -0.09352121, -0.00480929, -0.092729  ,\n",
       "          0.14803408, -0.06693411,  0.20826845,  0.11903678, -0.19753286,\n",
       "          0.20315863,  0.08476989,  0.15814252, -0.10572624,  0.1523002 ,\n",
       "          0.10445045, -0.19942828, -0.07060993, -0.11155838,  0.20128612,\n",
       "         -0.03302695, -0.19552352, -0.15211028,  0.22771235, -0.03822191],\n",
       "        [-0.15307917, -0.20183389, -0.18188915,  0.03776763, -0.02614602,\n",
       "          0.00239502,  0.13598238, -0.21744716, -0.01101257, -0.22436593,\n",
       "          0.13989608, -0.15422894,  0.17050813, -0.15194683, -0.01545341,\n",
       "          0.20364945,  0.02127381, -0.14977032, -0.07818139,  0.09873696,\n",
       "          0.10892354,  0.0126342 , -0.01887372,  0.1771123 , -0.04364634,\n",
       "          0.0916744 , -0.04361448, -0.1316407 ,  0.11394595, -0.02361941,\n",
       "          0.2056245 ,  0.20442264, -0.08669515, -0.10035665, -0.10150796,\n",
       "          0.10613014, -0.01479907, -0.03717667, -0.20162228,  0.01357298,\n",
       "          0.12920938, -0.01757012, -0.22771661, -0.16021998, -0.09728958,\n",
       "          0.16954683,  0.09646632,  0.01096229,  0.05185886, -0.12792687,\n",
       "          0.1612149 , -0.18944414,  0.22226228,  0.05257894, -0.07766217,\n",
       "         -0.13019781,  0.19476227,  0.04749529, -0.1461963 , -0.14281946,\n",
       "          0.06796037, -0.18607512, -0.18832873,  0.04613857, -0.14791794,\n",
       "         -0.11867008, -0.11827021, -0.1771209 ,  0.06859066, -0.20318103,\n",
       "         -0.23902988,  0.07976379,  0.0035596 , -0.22170973, -0.18331683,\n",
       "         -0.09463815, -0.04416999, -0.01234518,  0.01314251,  0.08164267,\n",
       "         -0.09858902, -0.10471849,  0.1455505 , -0.02426383,  0.23236437,\n",
       "         -0.0601642 , -0.20949352,  0.14500146, -0.2085785 , -0.15788218,\n",
       "         -0.12485842, -0.02066599, -0.13025719, -0.21038602, -0.15510839,\n",
       "         -0.02782902,  0.1337532 ,  0.1569279 ,  0.14754231,  0.19259806],\n",
       "        [ 0.04744868,  0.00096928,  0.21975155,  0.19694896, -0.2121833 ,\n",
       "          0.09014346, -0.22329596, -0.08148976, -0.14676942,  0.01482613,\n",
       "         -0.06521566, -0.14352334,  0.17887618, -0.0043758 , -0.02838932,\n",
       "          0.06003727,  0.03707339,  0.06358446,  0.01250048, -0.15657175,\n",
       "          0.07822351,  0.15363424, -0.1160394 , -0.03612691, -0.13451606,\n",
       "          0.2320397 , -0.06478131, -0.07068835, -0.23595642, -0.01565869,\n",
       "         -0.20965937,  0.09436537, -0.22916315, -0.09961027, -0.07566634,\n",
       "         -0.20415014, -0.05499129,  0.09403871,  0.1096835 , -0.10543808,\n",
       "          0.1996802 ,  0.17826594, -0.15901157,  0.17709969,  0.1401114 ,\n",
       "          0.10668702,  0.1709591 ,  0.22145434, -0.19979127,  0.05381583,\n",
       "         -0.02018216, -0.07744947, -0.11165944, -0.19061078,  0.02226059,\n",
       "          0.21612264,  0.01369764, -0.03012756, -0.04912661,  0.16092737,\n",
       "          0.07963865,  0.19861247,  0.18733905,  0.22172774, -0.04338838,\n",
       "         -0.11126602,  0.05357848, -0.17565897,  0.2359261 ,  0.00106429,\n",
       "         -0.0342356 , -0.05421185, -0.21155335,  0.02580987, -0.08849801,\n",
       "          0.05031393, -0.12629038, -0.02701847, -0.12515137, -0.02098514,\n",
       "          0.11631848, -0.23664758, -0.15253755,  0.12528126, -0.02607131,\n",
       "          0.22661613, -0.04606101, -0.06707966,  0.20378704,  0.15170057,\n",
       "         -0.02418017, -0.0017861 ,  0.10270841,  0.09650485, -0.02918318,\n",
       "          0.17173268,  0.14211293, -0.02672929, -0.12445976,  0.2294016 ],\n",
       "        [-0.1263082 ,  0.043963  ,  0.00410737, -0.11977865, -0.1788283 ,\n",
       "         -0.035485  ,  0.21836527,  0.20056735, -0.15270683, -0.00233784,\n",
       "         -0.1035165 , -0.03516795, -0.15250957, -0.1873415 ,  0.19524951,\n",
       "          0.12127362, -0.1353922 ,  0.08896662,  0.21268894, -0.07955292,\n",
       "          0.02842467,  0.15705009, -0.07334062,  0.1299588 ,  0.13562714,\n",
       "         -0.05664073,  0.23492412,  0.11185624, -0.19556308, -0.11317368,\n",
       "         -0.23742405, -0.10150784,  0.22056292, -0.16992179,  0.00520864,\n",
       "         -0.20522754, -0.20766895,  0.21911843,  0.07561614, -0.00849736,\n",
       "         -0.11301832, -0.01413357, -0.10631332, -0.01207794, -0.21783733,\n",
       "         -0.22443233,  0.09478508, -0.22130302,  0.12484623, -0.2289533 ,\n",
       "          0.02999435,  0.09517507, -0.1732415 , -0.10753143,  0.1824377 ,\n",
       "         -0.01583081,  0.04748224,  0.16880165, -0.1914936 , -0.17925249,\n",
       "         -0.2052863 , -0.18742476,  0.06033354, -0.01640593,  0.07083361,\n",
       "          0.14765294, -0.1842061 ,  0.17079373,  0.12038757,  0.23631547,\n",
       "         -0.0647833 ,  0.0554385 ,  0.12765382, -0.17711686, -0.20859896,\n",
       "          0.17741184, -0.20655712, -0.10698999, -0.20928425, -0.22655378,\n",
       "         -0.09257272, -0.07403794, -0.04469894, -0.10452078, -0.05089048,\n",
       "         -0.16326705,  0.13671546, -0.21826957, -0.18316466, -0.2176255 ,\n",
       "         -0.12088995, -0.1754399 ,  0.19087131, -0.15948974, -0.10809025,\n",
       "         -0.20301165, -0.16272664, -0.00176844,  0.21091424, -0.03987409],\n",
       "        [-0.04010564, -0.00110999,  0.08079107,  0.10426061, -0.19584416,\n",
       "          0.2025161 ,  0.14614387,  0.04669614,  0.22487949,  0.18742831,\n",
       "          0.01004386,  0.22347395,  0.1189409 , -0.13279554,  0.23201354,\n",
       "          0.15848033, -0.02662031,  0.22311951, -0.17033857, -0.1856874 ,\n",
       "          0.13310622, -0.06509255,  0.20430122, -0.12139269,  0.1658033 ,\n",
       "          0.16190703,  0.12256576,  0.10554363,  0.13693182, -0.13824579,\n",
       "         -0.15435371,  0.05288403, -0.17483634,  0.17140679,  0.0110331 ,\n",
       "          0.18839793,  0.2118748 , -0.07242839,  0.1293828 , -0.04977381,\n",
       "          0.1070108 ,  0.05155371,  0.18600564, -0.13769284,  0.13448499,\n",
       "         -0.00805134, -0.1467016 ,  0.22489055, -0.00873701, -0.04569769,\n",
       "         -0.16503099,  0.07106216, -0.03487279, -0.20276904, -0.01061174,\n",
       "         -0.11218758,  0.17474605,  0.16672383, -0.12430252,  0.12858047,\n",
       "          0.07477371, -0.1538899 ,  0.02718945,  0.12512623,  0.1895472 ,\n",
       "          0.03419052, -0.08570142,  0.20855848,  0.05167596, -0.10994388,\n",
       "         -0.19174449,  0.19967015, -0.23411173,  0.09744276, -0.04315203,\n",
       "         -0.1366656 ,  0.23611183, -0.16335215,  0.18418641, -0.04507071,\n",
       "         -0.14235008, -0.00725064, -0.15263486,  0.02547152,  0.07819347,\n",
       "          0.03881846, -0.21544386, -0.12863187,  0.22755964, -0.20579274,\n",
       "          0.10737686,  0.16246979, -0.16959041,  0.10664754, -0.19409767,\n",
       "          0.04527102,  0.21570842, -0.18120484, -0.21257466, -0.00346546]],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'dense_4/bias:0' shape=(100,) dtype=float32, numpy=\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       dtype=float32)>]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 使用layer.vairables可以输出该层中的所有用以运算的参数，每个神经元对应的w权重和b偏置\n",
    "layer.variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'dense_4/kernel:0' shape=(5, 100) dtype=float32, numpy=\n",
      "array([[-0.00516658,  0.16830744,  0.10691567, -0.22209494, -0.06649332,\n",
      "         0.05231564,  0.15315811, -0.09568574,  0.09581386, -0.05721094,\n",
      "         0.0339296 ,  0.07436655,  0.12737592,  0.03646921,  0.23837589,\n",
      "        -0.120244  ,  0.01287107, -0.04214725,  0.10307647, -0.17928588,\n",
      "         0.18581615,  0.22529308,  0.16231619, -0.23440531, -0.21285775,\n",
      "        -0.0251063 , -0.08228214,  0.03245674,  0.09435289, -0.02554134,\n",
      "        -0.18795732,  0.01307149, -0.05182236,  0.03192033, -0.15838663,\n",
      "         0.08954953, -0.15672375, -0.04879673,  0.06885518,  0.18610577,\n",
      "        -0.02400839, -0.09453568,  0.2021644 , -0.21577266, -0.1640091 ,\n",
      "        -0.17140542, -0.02432066,  0.11728613, -0.03578222, -0.06294683,\n",
      "         0.01608585,  0.05855079,  0.00970368, -0.02924605, -0.19812946,\n",
      "         0.03949587,  0.18871959, -0.09425402, -0.22173081,  0.02184044,\n",
      "        -0.08302584, -0.12884018,  0.09550656,  0.11684261, -0.1650645 ,\n",
      "        -0.07400031, -0.21054265, -0.03787221,  0.02960138,  0.22187705,\n",
      "         0.07314532,  0.11003558, -0.11766295,  0.16839425, -0.12722455,\n",
      "        -0.18331876,  0.1026981 , -0.09352121, -0.00480929, -0.092729  ,\n",
      "         0.14803408, -0.06693411,  0.20826845,  0.11903678, -0.19753286,\n",
      "         0.20315863,  0.08476989,  0.15814252, -0.10572624,  0.1523002 ,\n",
      "         0.10445045, -0.19942828, -0.07060993, -0.11155838,  0.20128612,\n",
      "        -0.03302695, -0.19552352, -0.15211028,  0.22771235, -0.03822191],\n",
      "       [-0.15307917, -0.20183389, -0.18188915,  0.03776763, -0.02614602,\n",
      "         0.00239502,  0.13598238, -0.21744716, -0.01101257, -0.22436593,\n",
      "         0.13989608, -0.15422894,  0.17050813, -0.15194683, -0.01545341,\n",
      "         0.20364945,  0.02127381, -0.14977032, -0.07818139,  0.09873696,\n",
      "         0.10892354,  0.0126342 , -0.01887372,  0.1771123 , -0.04364634,\n",
      "         0.0916744 , -0.04361448, -0.1316407 ,  0.11394595, -0.02361941,\n",
      "         0.2056245 ,  0.20442264, -0.08669515, -0.10035665, -0.10150796,\n",
      "         0.10613014, -0.01479907, -0.03717667, -0.20162228,  0.01357298,\n",
      "         0.12920938, -0.01757012, -0.22771661, -0.16021998, -0.09728958,\n",
      "         0.16954683,  0.09646632,  0.01096229,  0.05185886, -0.12792687,\n",
      "         0.1612149 , -0.18944414,  0.22226228,  0.05257894, -0.07766217,\n",
      "        -0.13019781,  0.19476227,  0.04749529, -0.1461963 , -0.14281946,\n",
      "         0.06796037, -0.18607512, -0.18832873,  0.04613857, -0.14791794,\n",
      "        -0.11867008, -0.11827021, -0.1771209 ,  0.06859066, -0.20318103,\n",
      "        -0.23902988,  0.07976379,  0.0035596 , -0.22170973, -0.18331683,\n",
      "        -0.09463815, -0.04416999, -0.01234518,  0.01314251,  0.08164267,\n",
      "        -0.09858902, -0.10471849,  0.1455505 , -0.02426383,  0.23236437,\n",
      "        -0.0601642 , -0.20949352,  0.14500146, -0.2085785 , -0.15788218,\n",
      "        -0.12485842, -0.02066599, -0.13025719, -0.21038602, -0.15510839,\n",
      "        -0.02782902,  0.1337532 ,  0.1569279 ,  0.14754231,  0.19259806],\n",
      "       [ 0.04744868,  0.00096928,  0.21975155,  0.19694896, -0.2121833 ,\n",
      "         0.09014346, -0.22329596, -0.08148976, -0.14676942,  0.01482613,\n",
      "        -0.06521566, -0.14352334,  0.17887618, -0.0043758 , -0.02838932,\n",
      "         0.06003727,  0.03707339,  0.06358446,  0.01250048, -0.15657175,\n",
      "         0.07822351,  0.15363424, -0.1160394 , -0.03612691, -0.13451606,\n",
      "         0.2320397 , -0.06478131, -0.07068835, -0.23595642, -0.01565869,\n",
      "        -0.20965937,  0.09436537, -0.22916315, -0.09961027, -0.07566634,\n",
      "        -0.20415014, -0.05499129,  0.09403871,  0.1096835 , -0.10543808,\n",
      "         0.1996802 ,  0.17826594, -0.15901157,  0.17709969,  0.1401114 ,\n",
      "         0.10668702,  0.1709591 ,  0.22145434, -0.19979127,  0.05381583,\n",
      "        -0.02018216, -0.07744947, -0.11165944, -0.19061078,  0.02226059,\n",
      "         0.21612264,  0.01369764, -0.03012756, -0.04912661,  0.16092737,\n",
      "         0.07963865,  0.19861247,  0.18733905,  0.22172774, -0.04338838,\n",
      "        -0.11126602,  0.05357848, -0.17565897,  0.2359261 ,  0.00106429,\n",
      "        -0.0342356 , -0.05421185, -0.21155335,  0.02580987, -0.08849801,\n",
      "         0.05031393, -0.12629038, -0.02701847, -0.12515137, -0.02098514,\n",
      "         0.11631848, -0.23664758, -0.15253755,  0.12528126, -0.02607131,\n",
      "         0.22661613, -0.04606101, -0.06707966,  0.20378704,  0.15170057,\n",
      "        -0.02418017, -0.0017861 ,  0.10270841,  0.09650485, -0.02918318,\n",
      "         0.17173268,  0.14211293, -0.02672929, -0.12445976,  0.2294016 ],\n",
      "       [-0.1263082 ,  0.043963  ,  0.00410737, -0.11977865, -0.1788283 ,\n",
      "        -0.035485  ,  0.21836527,  0.20056735, -0.15270683, -0.00233784,\n",
      "        -0.1035165 , -0.03516795, -0.15250957, -0.1873415 ,  0.19524951,\n",
      "         0.12127362, -0.1353922 ,  0.08896662,  0.21268894, -0.07955292,\n",
      "         0.02842467,  0.15705009, -0.07334062,  0.1299588 ,  0.13562714,\n",
      "        -0.05664073,  0.23492412,  0.11185624, -0.19556308, -0.11317368,\n",
      "        -0.23742405, -0.10150784,  0.22056292, -0.16992179,  0.00520864,\n",
      "        -0.20522754, -0.20766895,  0.21911843,  0.07561614, -0.00849736,\n",
      "        -0.11301832, -0.01413357, -0.10631332, -0.01207794, -0.21783733,\n",
      "        -0.22443233,  0.09478508, -0.22130302,  0.12484623, -0.2289533 ,\n",
      "         0.02999435,  0.09517507, -0.1732415 , -0.10753143,  0.1824377 ,\n",
      "        -0.01583081,  0.04748224,  0.16880165, -0.1914936 , -0.17925249,\n",
      "        -0.2052863 , -0.18742476,  0.06033354, -0.01640593,  0.07083361,\n",
      "         0.14765294, -0.1842061 ,  0.17079373,  0.12038757,  0.23631547,\n",
      "        -0.0647833 ,  0.0554385 ,  0.12765382, -0.17711686, -0.20859896,\n",
      "         0.17741184, -0.20655712, -0.10698999, -0.20928425, -0.22655378,\n",
      "        -0.09257272, -0.07403794, -0.04469894, -0.10452078, -0.05089048,\n",
      "        -0.16326705,  0.13671546, -0.21826957, -0.18316466, -0.2176255 ,\n",
      "        -0.12088995, -0.1754399 ,  0.19087131, -0.15948974, -0.10809025,\n",
      "        -0.20301165, -0.16272664, -0.00176844,  0.21091424, -0.03987409],\n",
      "       [-0.04010564, -0.00110999,  0.08079107,  0.10426061, -0.19584416,\n",
      "         0.2025161 ,  0.14614387,  0.04669614,  0.22487949,  0.18742831,\n",
      "         0.01004386,  0.22347395,  0.1189409 , -0.13279554,  0.23201354,\n",
      "         0.15848033, -0.02662031,  0.22311951, -0.17033857, -0.1856874 ,\n",
      "         0.13310622, -0.06509255,  0.20430122, -0.12139269,  0.1658033 ,\n",
      "         0.16190703,  0.12256576,  0.10554363,  0.13693182, -0.13824579,\n",
      "        -0.15435371,  0.05288403, -0.17483634,  0.17140679,  0.0110331 ,\n",
      "         0.18839793,  0.2118748 , -0.07242839,  0.1293828 , -0.04977381,\n",
      "         0.1070108 ,  0.05155371,  0.18600564, -0.13769284,  0.13448499,\n",
      "        -0.00805134, -0.1467016 ,  0.22489055, -0.00873701, -0.04569769,\n",
      "        -0.16503099,  0.07106216, -0.03487279, -0.20276904, -0.01061174,\n",
      "        -0.11218758,  0.17474605,  0.16672383, -0.12430252,  0.12858047,\n",
      "         0.07477371, -0.1538899 ,  0.02718945,  0.12512623,  0.1895472 ,\n",
      "         0.03419052, -0.08570142,  0.20855848,  0.05167596, -0.10994388,\n",
      "        -0.19174449,  0.19967015, -0.23411173,  0.09744276, -0.04315203,\n",
      "        -0.1366656 ,  0.23611183, -0.16335215,  0.18418641, -0.04507071,\n",
      "        -0.14235008, -0.00725064, -0.15263486,  0.02547152,  0.07819347,\n",
      "         0.03881846, -0.21544386, -0.12863187,  0.22755964, -0.20579274,\n",
      "         0.10737686,  0.16246979, -0.16959041,  0.10664754, -0.19409767,\n",
      "         0.04527102,  0.21570842, -0.18120484, -0.21257466, -0.00346546]],\n",
      "      dtype=float32)>\n",
      "----------------------------------------------------------------------------------------------------\n",
      "<tf.Variable 'dense_4/bias:0' shape=(100,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "      dtype=float32)>\n"
     ]
    }
   ],
   "source": [
    "print(layer.kernel) \n",
    "print(\"-\" * 50)\n",
    "print(layer.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "\n",
    "housing = fetch_california_housing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train_all, x_test, y_train_all, y_test = train_test_split(\n",
    "    housing.data, housing.target, random_state = 7)\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(\n",
    "    x_train_all, y_train_all, random_state = 11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "x_train_scaled = scaler.fit_transform(x_train)\n",
    "x_valid_scaled = scaler.transform(x_valid)\n",
    "x_test_scaled = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([4.5417706e-05 6.7153489e-03 6.9314718e-01 5.0067153e+00 1.0000046e+01], shape=(5,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# 自定义激活函数softplus，使用lambda实现，计算log(exp(features)+1)\n",
    "# 输入x，对x进行softplus运算并返回\n",
    "customized_softplus = keras.layers.Lambda(lambda x : tf.nn.softplus(x))\n",
    "\n",
    "# print(customized_softplus([-10., -5., 0., 5., 10.]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对模型各层进行自定义设置\n",
    "# 继承父类keras.layers.Layer\n",
    "class CustomizedDenseLayer(keras.layers.Layer):\n",
    "    \n",
    "    # 初始化\n",
    "    def __init__(self, units, activation=None, **kwargs):\n",
    "        # 神经元数\n",
    "        self.units = units\n",
    "        # 激活函数\n",
    "        self.activation = keras.layers.Activation(activation)\n",
    "        # 初始化父类\n",
    "        super(CustomizedDenseLayer, self).__init__(**kwargs)\n",
    "    \n",
    "    # 构建模型\n",
    "    def build(self, input_shape):\n",
    "        # 设置权重和偏置值\n",
    "        # 设置形状 (输入数据的列, 神经元数)\n",
    "        self.kernel = self.add_weight(name='kernel',\n",
    "                                     shape=(input_shape[1], self.units),\n",
    "                                     initializer='uniform',\n",
    "                                     trainable=True)\n",
    "        \n",
    "        # 设置形状 (神经元数,)，偏置初始化为0\n",
    "        self.bias = self.add_weight(name='bias',\n",
    "                                   shape=(self.units,),\n",
    "                                   initializer='zeros',\n",
    "                                   trainable=True)\n",
    "        \n",
    "    # 设置数据在模型中流动时发生的运算\n",
    "    def call(self, x):\n",
    "        \n",
    "        # x是数据矩阵，self.kernel是权重，self.bias是偏置，@是将后面矩阵转置后的矩阵相乘操作\n",
    "        # 其实就是y=wx+b\n",
    "        return self.activation(x @ self.kernel + self.bias)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "customized_dense_layer_6 (Cu (None, 30)                270       \n",
      "_________________________________________________________________\n",
      "customized_dense_layer_7 (Cu (None, 1)                 31        \n",
      "_________________________________________________________________\n",
      "lambda_2 (Lambda)            (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 301\n",
      "Trainable params: 301\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 构建模型\n",
    "model = keras.models.Sequential([\n",
    "    # 一般添加层的方式\n",
    "    CustomizedDenseLayer(30, activation='relu',\n",
    "                         input_shape=x_train.shape[1:]),\n",
    "    CustomizedDenseLayer(1),\n",
    "    \n",
    "    # 添加自定义激活函数层\n",
    "    customized_softplus,\n",
    "])\n",
    "\n",
    "# 模型的概述\n",
    "model.summary()\n",
    "\n",
    "# 编译模型\n",
    "model.compile(loss='mean_squared_error', optimizer='sgd')\n",
    "\n",
    "# 指定回调函数\n",
    "callbacks = [keras.callbacks.EarlyStopping(\n",
    "    patience=5, min_delta=1e-3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 1.2234 - val_loss: 0.6862\n",
      "Epoch 2/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5997 - val_loss: 0.5933\n",
      "Epoch 3/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5234 - val_loss: 0.5227\n",
      "Epoch 4/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4779 - val_loss: 0.4914\n",
      "Epoch 5/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4552 - val_loss: 0.4713\n",
      "Epoch 6/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4420 - val_loss: 0.4649\n",
      "Epoch 7/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4323 - val_loss: 0.4503\n",
      "Epoch 8/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4241 - val_loss: 0.4459\n",
      "Epoch 9/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4216 - val_loss: 0.4379\n",
      "Epoch 10/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4189 - val_loss: 0.4211\n",
      "Epoch 11/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3996 - val_loss: 0.4097\n",
      "Epoch 12/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3929 - val_loss: 0.4137\n",
      "Epoch 13/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3874 - val_loss: 0.4000\n",
      "Epoch 14/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3835 - val_loss: 0.4019\n",
      "Epoch 15/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3814 - val_loss: 0.3968\n",
      "Epoch 16/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3779 - val_loss: 0.3955\n",
      "Epoch 17/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3772 - val_loss: 0.3908\n",
      "Epoch 18/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3745 - val_loss: 0.4020\n",
      "Epoch 19/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3731 - val_loss: 0.3871\n",
      "Epoch 20/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3715 - val_loss: 0.3862\n",
      "Epoch 21/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3713 - val_loss: 0.3924\n",
      "Epoch 22/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3699 - val_loss: 0.3820\n",
      "Epoch 23/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3687 - val_loss: 0.3826\n",
      "Epoch 24/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3678 - val_loss: 0.3862\n",
      "Epoch 25/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3676 - val_loss: 0.3818\n",
      "Epoch 26/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3661 - val_loss: 0.3822\n",
      "Epoch 27/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3657 - val_loss: 0.3835\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train_scaled, y_train,\n",
    "                    validation_data = (x_valid_scaled, y_valid),\n",
    "                    epochs = 100,\n",
    "                    callbacks = callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_learning_curves(history):\n",
    "    pd.DataFrame(history.history).plot(figsize=(8, 5))\n",
    "    plt.grid(True)\n",
    "    plt.gca().set_ylim(0, 1)\n",
    "    plt.show()\n",
    "    \n",
    "plot_learning_curves(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.38716524839401245"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test_scaled, y_test, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
